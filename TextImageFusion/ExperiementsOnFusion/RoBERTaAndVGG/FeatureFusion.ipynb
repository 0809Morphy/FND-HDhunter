{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-05T11:17:38.269502700Z",
     "start_time": "2024-04-05T11:17:31.702422Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from PIL import Image\n",
    "\n",
    "# 文本编码器 - 使用RoBERTa\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "    def forward(self, text):\n",
    "        inputs = self.tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        outputs = self.roberta(**inputs)\n",
    "        text_embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        return text_embeddings\n",
    "\n",
    "# 图像编码器 - 使用VGG\n",
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageEncoder, self).__init__()\n",
    "        # 加载预训练的VGG模型\n",
    "        self.model = models.vgg16(pretrained=True)\n",
    "        # 替换VGG的分类器部分以匹配文本编码器的输出维度\n",
    "        self.model.classifier[6] = nn.Linear(self.model.classifier[6].in_features, 768)\n",
    "\n",
    "    def forward(self, images):\n",
    "        img_embeddings = self.model(images)\n",
    "        return img_embeddings\n",
    "\n",
    "# 融合模块\n",
    "class FusionModule(nn.Module):\n",
    "    def __init__(self, text_encoder, image_encoder):\n",
    "        super(FusionModule, self).__init__()\n",
    "        self.text_encoder = text_encoder\n",
    "        self.image_encoder = image_encoder\n",
    "        # 维持原有的融合策略\n",
    "        self.fusion = nn.Linear(1536, 768)\n",
    "\n",
    "    def forward(self, text, images):\n",
    "        text_embeddings = self.text_encoder(text)\n",
    "        img_embeddings = self.image_encoder(images)\n",
    "        fused_embeddings = torch.cat((text_embeddings, img_embeddings), dim=1)\n",
    "        fused_embeddings = self.fusion(fused_embeddings)\n",
    "        return fused_embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text and image are predicted as real.\n"
     ]
    }
   ],
   "source": [
    "# 图像预处理函数，维持不变\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    img_tensor = preprocess(image)\n",
    "    img_tensor = img_tensor.unsqueeze(0)  # 增加批次维度\n",
    "    return img_tensor\n",
    "\n",
    "# 分类器模块，维持不变\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, fusion_output_size):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(fusion_output_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, fusion_output):\n",
    "        logits = self.classifier(fusion_output)\n",
    "        return logits\n",
    "\n",
    "# 使用示例\n",
    "text_encoder = TextEncoder()\n",
    "image_encoder = ImageEncoder()\n",
    "fusion_module = FusionModule(text_encoder, image_encoder)\n",
    "classifier = Classifier(fusion_output_size=768)\n",
    "\n",
    "# 这里的文本和图像路径保持不变，确保你的图像路径是正确的\n",
    "text = \"This is a spiderman with black suit\"\n",
    "image_path = \"../Spiderman1.png\"\n",
    "images = preprocess_image(image_path)\n",
    "\n",
    "fused_embeddings = fusion_module(text, images)\n",
    "logits = classifier(fused_embeddings)\n",
    "predicted = torch.argmax(logits, dim=1)\n",
    "\n",
    "if predicted == 0:\n",
    "    print(\"The text and image are predicted as real.\")\n",
    "else:\n",
    "    print(\"The text and image are predicted as fake.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T11:30:13.034794500Z",
     "start_time": "2024-04-05T11:30:10.259116300Z"
    }
   },
   "id": "c4955bb81671b4c5",
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
